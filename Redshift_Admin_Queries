-- find which tables have been granted to a group and also which users have been added to the group
select g.groname,u.usename FROM pg_group g, pg_user u WHERE u.usesysid = ANY(g.grolist) ORDER BY 1,2;

SELECT
    u.usename,
    s.schemaname,
    has_schema_privilege(u.usename,s.schemaname,'create') AS user_has_select_permission,
    has_schema_privilege(u.usename,s.schemaname,'usage') AS user_has_usage_permission
FROM
    pg_user u
CROSS JOIN
    (SELECT DISTINCT schemaname FROM pg_tables) s
WHERE
    u.usename = 'awsuser'
;

-- View table ID, database, schema, and table name
select distinct(id) table_id
,trim(datname)   db_name
,trim(nspname)   schema_name
,trim(relname)   table_name
from stv_tbl_perm
join pg_class on pg_class.oid = stv_tbl_perm.id
join pg_namespace on pg_namespace.oid = relnamespace
join pg_database on pg_database.oid = stv_tbl_perm.db_id;

-- List the number of columns per Amazon Redshift table
select nspname, relname, max(attnum) as num_cols
from pg_attribute a, pg_namespace n, pg_class c
where n.oid = c.relnamespace and  a.attrelid = c.oid
and c.relname not like '%pkey'
and n.nspname not like 'pg%'
and n.nspname not like 'information%'
group by 1, 2
order by 1, 2;

-- List the schemas and table row count in a database
select datname, nspname, relname, sum(rows) as rows
from pg_class, pg_namespace, pg_database, stv_tbl_perm
where pg_namespace.oid = relnamespace
and pg_class.oid = stv_tbl_perm.id
and pg_database.oid = stv_tbl_perm.db_id
and datname ='dev'
group by datname, nspname, relname
order by datname, nspname, relname;

-- List table IDs, data types, column names, and table names
select distinct attrelid, rtrim(name), attname, typname
from pg_attribute a, pg_type t, stv_tbl_perm p
where t.oid=a.atttypid and a.attrelid=p.id
and a.attrelid between 100100 and 110000
and typname not in('oid','xid','tid','cid')
order by a.attrelid asc, typname, attname;

-- Count the number of data blocks for each column in a table
select col, count(*)
from stv_blocklist s, pg_class p
where s.tbl=p.oid and relname='lineorder'
group by col
order by col;

***** Analysis of skewness at slice or stream level

--SVL_QUERY_REPORT - Shows steps and statistics in more detail than in the query, at slice level;
--SVL_QUERY_SUMMARY - Shows steps and statistics in more detail than in the query,at stream level; 

select query, elapsed, substring
from svl_qlog
order by query
desc limit 5;  

-- Order the results by segment, step, elapsed_time, and rows; if one slice has more value that means its skewed
select * from svl_query_report where query = MyQueryID order by segment, step, elapsed_time, rows;

-- Identifying queries with nested loops
select query, trim(querytxt) as SQL, starttime 
from stl_query 
where query in (
select distinct query 
from stl_alert_event_log 
where event like 'Nested Loop Join in the query plan%') 
order by starttime desc;

-- Top 50 bad queries 
select trim(database) as db, count(query) as n_qry, 
max(substring (qrytext,1,80)) as qrytext, 
min(run_minutes) as "min" , 
max(run_minutes) as "max", 
avg(run_minutes) as "avg", sum(run_minutes) as total,  
max(query) as max_query_id, 
max(starttime)::date as last_run, 
sum(alerts) as alerts, aborted
from (select userid, label, stl_query.query, 
trim(database) as database, 
trim(querytxt) as qrytext, 
md5(trim(querytxt)) as qry_md5, 
starttime, endtime, 
(datediff(seconds, starttime,endtime)::numeric(12,2))/60 as run_minutes,     
alrt.num_events as alerts, aborted 
from stl_query 
left outer join 
(select query, 1 as num_events from stl_alert_event_log group by query ) as alrt 
on alrt.query = stl_query.query
where userid <> 1 and starttime >=  dateadd(day, -7, current_date)) 
group by database, label, qry_md5, aborted
order by total desc limit 50;

-- if skew is > 4 change distribution style, pct_unsorted > 20%; run Vacuum, 
select trim(pgn.nspname) as schema, 
trim(a.name) as table, id as tableid, 
decode(pgc.reldiststyle,0, 'even',1,det.distkey ,8,'all') as distkey, dist_ratio.ratio::decimal(10,4) as skew, 
det.head_sort as "sortkey", 
det.n_sortkeys as "#sks", b.mbytes,  
decode(b.mbytes,0,0,((b.mbytes/part.total::decimal)*100)::decimal(5,2)) as pct_of_total, 
decode(det.max_enc,0,'n','y') as enc, a.rows, 
decode( det.n_sortkeys, 0, null, a.unsorted_rows ) as unsorted_rows , 
decode( det.n_sortkeys, 0, null, decode( a.rows,0,0, (a.unsorted_rows::decimal(32)/a.rows)*100) )::decimal(5,2) as pct_unsorted 
from (select db_id, id, name, sum(rows) as rows, 
sum(rows)-sum(sorted_rows) as unsorted_rows 
from stv_tbl_perm a 
group by db_id, id, name) as a 
join pg_class as pgc on pgc.oid = a.id
join pg_namespace as pgn on pgn.oid = pgc.relnamespace
left outer join (select tbl, count(*) as mbytes 
from stv_blocklist group by tbl) b on a.id=b.tbl
inner join (select attrelid, 
min(case attisdistkey when 't' then attname else null end) as "distkey",
min(case attsortkeyord when 1 then attname  else null end ) as head_sort , 
max(attsortkeyord) as n_sortkeys, 
max(attencodingtype) as max_enc 
from pg_attribute group by 1) as det 
on det.attrelid = a.id
inner join ( select tbl, max(mbytes)::decimal(32)/min(mbytes) as ratio 
from (select tbl, trim(name) as name, slice, count(*) as mbytes
from svv_diskusage group by tbl, name, slice ) 
group by tbl, name ) as dist_ratio on a.id = dist_ratio.tbl
join ( select sum(capacity) as  total
from stv_partitions where part_begin=0 ) as part on 1=1
where mbytes is not null 
order by  mbytes desc;

-- If min value is high look for ANALYZE or VACUUM, count is high; check STL_ALERT_EVENT_LOG
select trim(s.perm_table_name) as table, 
(sum(abs(datediff(seconds, s.starttime, s.endtime)))/60)::numeric(24,0) as minutes, 
trim(split_part(l.event,':',1)) as event,  trim(l.solution) as solution, 
max(l.query) as sample_query, count(*) 
from stl_alert_event_log as l 
left join stl_scan as s on s.query = l.query and s.slice = l.slice 
and s.segment = l.segment and s.step = l.step
where l.event_time >=  dateadd(day, -7, current_Date) 
group by 1,3,4 
order by 2 desc,6 desc;

-- Missing stats; Run Analyze command
select substring(trim(plannode),1,100) as plannode, count(*) 
from stl_explain 
where plannode like '%missing statistics%' 
group by plannode 
order by 2 desc;

-- Free storage space in Cluster
-- Its Nominal Disk Space (which customer is entitled for) not Raw disk space that is used by Redshift (for 160GB, more 160GB(adjacent node backup space) + 80GB(Metadata storage))
select sum(capacity)/1024 as capacity_gb, sum(used)/1024 as used_gb,(capacity_gb - used_gb) as free_gb
from stv_partitions where part_begin =0;

-- It says if drive is failed in disk
select * from stv_partitions  where failed = 1;

--- SP Step and debug step -- 
select * from SVL_STORED_PROC_CALL
where querytxt like '%hdl_services_sp.sp_srv_asset_sals_revn_opp_cds_smax_fs_bipin_v4_stgabove_v1()%'
--order by starttime desc; 
select * from SVL_STORED_PROC_MESSAGES 
where xid in ('12565099') and pid in (21505) 
order by recordtime;

-- Query to give execution done in particular PID
SELECT a.query, 
       b.starttime, 
       b.endtime, 
       ( b.endtime - b.starttime ) / 1000000 AS duration_sec, 
       Round(a.query_cpu_usage_percent)      AS cpu_usage_percent, 
       Substring(b.querytxt, 1, 80)          AS querytxt 
FROM   svl_query_metrics_summary a, 
       stl_query b 
WHERE  a.query = b.query 
       and b.pid=pg_backend_pid()
       AND b.starttime BETWEEN Dateadd(hour, -1, sysdate) AND sysdate 
       AND a.userid > 1 
ORDER  BY b.starttime DESC;

--See already inflight query and kill them if blocking your query
-- Inflight query (Running Query)
select
  userid
  , query
  , pid
  , starttime
  , text as text
from stv_inflight;

--KIll query
cancel PID;

-- Get the column name and its number for all views 
SELECT trim(pgn.nspname) AS schema_name, 
       trim(pgc.relname) AS view_name,
       det.attnum        AS column_num,
       det.attname       AS column_name,
       def.type          AS data_type
FROM pg_class as pgc
JOIN pg_namespace as pgn on pgn.oid = pgc.relnamespace
LEFT OUTER JOIN (select attrelid, attname, attnum from pg_attribute where attnum>0) as det on det.attrelid = pgc.oid
LEFT OUTER JOIN pg_table_def def on (def.schemaname=pgn.nspname and def.tablename=pgc.relname and def."column"=det.attname)
WHERE schema_name NOT IN ('pg_catalog','pg_toast','information_schema')
AND pgc.relkind ='v' 
order by 1,2,3;

--  list of all the queries running longer then 30 min
select 
  pid, 
  trim(user_name) AS user_name, 
  starttime, 
  query, 
  DATEDIFF(minutes, starttime, getdate()) as delay_in_mints, 
  status
from stv_recents 
where 
  status='Running' and  
  DATEDIFF(minutes, starttime, getdate()) > 30
order by starttime;

-- find which tables have been granted to a group and also which users have been added to the group
select g.groname,u.usename FROM pg_group g, pg_user u WHERE u.usesysid = ANY(g.grolist) ORDER BY 1,2;

SELECT
    u.usename,
    s.schemaname,
    has_schema_privilege(u.usename,s.schemaname,'create') AS user_has_select_permission,
    has_schema_privilege(u.usename,s.schemaname,'usage') AS user_has_usage_permission
FROM
    pg_user u
CROSS JOIN
    (SELECT DISTINCT schemaname FROM pg_tables) s
WHERE
    u.usename = 'awsuser'
;

-- View table ID, database, schema, and table name
select distinct(id) table_id
,trim(datname)   db_name
,trim(nspname)   schema_name
,trim(relname)   table_name
from stv_tbl_perm
join pg_class on pg_class.oid = stv_tbl_perm.id
join pg_namespace on pg_namespace.oid = relnamespace
join pg_database on pg_database.oid = stv_tbl_perm.db_id;

-- List the number of columns per Amazon Redshift table
select nspname, relname, max(attnum) as num_cols
from pg_attribute a, pg_namespace n, pg_class c
where n.oid = c.relnamespace and  a.attrelid = c.oid
and c.relname not like '%pkey'
and n.nspname not like 'pg%'
and n.nspname not like 'information%'
group by 1, 2
order by 1, 2;

-- List the schemas and table row count in a database
select datname, nspname, relname, sum(rows) as rows
from pg_class, pg_namespace, pg_database, stv_tbl_perm
where pg_namespace.oid = relnamespace
and pg_class.oid = stv_tbl_perm.id
and pg_database.oid = stv_tbl_perm.db_id
and datname ='dev'
group by datname, nspname, relname
order by datname, nspname, relname;

-- List table IDs, data types, column names, and table names
select distinct attrelid, rtrim(name), attname, typname
from pg_attribute a, pg_type t, stv_tbl_perm p
where t.oid=a.atttypid and a.attrelid=p.id
and a.attrelid between 100100 and 110000
and typname not in('oid','xid','tid','cid')
order by a.attrelid asc, typname, attname;

-- Count the number of data blocks for each column in a table
select col, count(*)
from stv_blocklist s, pg_class p
where s.tbl=p.oid and relname='lineorder'
group by col
order by col;

***** Analysis of skewness at slice or stream level

--SVL_QUERY_REPORT - Shows steps and statistics in more detail than in the query, at slice level;
--SVL_QUERY_SUMMARY - Shows steps and statistics in more detail than in the query,at stream level; 

select query, elapsed, substring
from svl_qlog
order by query
desc limit 5;  

-- Order the results by segment, step, elapsed_time, and rows; if one slice has more value that means its skewed
select * from svl_query_report where query = MyQueryID order by segment, step, elapsed_time, rows;

-- Identifying queries with nested loops
select query, trim(querytxt) as SQL, starttime 
from stl_query 
where query in (
select distinct query 
from stl_alert_event_log 
where event like 'Nested Loop Join in the query plan%') 
order by starttime desc;

-- Top 50 bad queries 
select trim(database) as db, count(query) as n_qry, 
max(substring (qrytext,1,80)) as qrytext, 
min(run_minutes) as "min" , 
max(run_minutes) as "max", 
avg(run_minutes) as "avg", sum(run_minutes) as total,  
max(query) as max_query_id, 
max(starttime)::date as last_run, 
sum(alerts) as alerts, aborted
from (select userid, label, stl_query.query, 
trim(database) as database, 
trim(querytxt) as qrytext, 
md5(trim(querytxt)) as qry_md5, 
starttime, endtime, 
(datediff(seconds, starttime,endtime)::numeric(12,2))/60 as run_minutes,     
alrt.num_events as alerts, aborted 
from stl_query 
left outer join 
(select query, 1 as num_events from stl_alert_event_log group by query ) as alrt 
on alrt.query = stl_query.query
where userid <> 1 and starttime >=  dateadd(day, -7, current_date)) 
group by database, label, qry_md5, aborted
order by total desc limit 50;

-- if skew is > 4 change distribution style, pct_unsorted > 20%; run Vacuum, 
select trim(pgn.nspname) as schema, 
trim(a.name) as table, id as tableid, 
decode(pgc.reldiststyle,0, 'even',1,det.distkey ,8,'all') as distkey, dist_ratio.ratio::decimal(10,4) as skew, 
det.head_sort as "sortkey", 
det.n_sortkeys as "#sks", b.mbytes,  
decode(b.mbytes,0,0,((b.mbytes/part.total::decimal)*100)::decimal(5,2)) as pct_of_total, 
decode(det.max_enc,0,'n','y') as enc, a.rows, 
decode( det.n_sortkeys, 0, null, a.unsorted_rows ) as unsorted_rows , 
decode( det.n_sortkeys, 0, null, decode( a.rows,0,0, (a.unsorted_rows::decimal(32)/a.rows)*100) )::decimal(5,2) as pct_unsorted 
from (select db_id, id, name, sum(rows) as rows, 
sum(rows)-sum(sorted_rows) as unsorted_rows 
from stv_tbl_perm a 
group by db_id, id, name) as a 
join pg_class as pgc on pgc.oid = a.id
join pg_namespace as pgn on pgn.oid = pgc.relnamespace
left outer join (select tbl, count(*) as mbytes 
from stv_blocklist group by tbl) b on a.id=b.tbl
inner join (select attrelid, 
min(case attisdistkey when 't' then attname else null end) as "distkey",
min(case attsortkeyord when 1 then attname  else null end ) as head_sort , 
max(attsortkeyord) as n_sortkeys, 
max(attencodingtype) as max_enc 
from pg_attribute group by 1) as det 
on det.attrelid = a.id
inner join ( select tbl, max(mbytes)::decimal(32)/min(mbytes) as ratio 
from (select tbl, trim(name) as name, slice, count(*) as mbytes
from svv_diskusage group by tbl, name, slice ) 
group by tbl, name ) as dist_ratio on a.id = dist_ratio.tbl
join ( select sum(capacity) as  total
from stv_partitions where part_begin=0 ) as part on 1=1
where mbytes is not null 
order by  mbytes desc;

-- If min value is high look for ANALYZE or VACUUM, count is high; check STL_ALERT_EVENT_LOG
select trim(s.perm_table_name) as table, 
(sum(abs(datediff(seconds, s.starttime, s.endtime)))/60)::numeric(24,0) as minutes, 
trim(split_part(l.event,':',1)) as event,  trim(l.solution) as solution, 
max(l.query) as sample_query, count(*) 
from stl_alert_event_log as l 
left join stl_scan as s on s.query = l.query and s.slice = l.slice 
and s.segment = l.segment and s.step = l.step
where l.event_time >=  dateadd(day, -7, current_Date) 
group by 1,3,4 
order by 2 desc,6 desc;

-- Missing stats; Run Analyze command
select substring(trim(plannode),1,100) as plannode, count(*) 
from stl_explain 
where plannode like '%missing statistics%' 
group by plannode 
order by 2 desc;

-- Free storage space in Cluster
-- Its Nominal Disk Space (which customer is entitled for) not Raw disk space that is used by Redshift (for 160GB, more 160GB(adjacent node backup space) + 80GB(Metadata storage))
select sum(capacity)/1024 as capacity_gb, sum(used)/1024 as used_gb,(capacity_gb - used_gb) as free_gb
from stv_partitions where part_begin =0;

-- It says if drive is failed in disk
select * from stv_partitions  where failed = 1;

--- SP Step and debug step -- 
select * from SVL_STORED_PROC_CALL
where querytxt like '%hdl_services_sp.sp_srv_asset_sals_revn_opp_cds_smax_fs_bipin_v4_stgabove_v1()%'
--order by starttime desc; 
select * from SVL_STORED_PROC_MESSAGES 
where xid in ('12565099') and pid in (21505) 
order by recordtime;

-- Query to give execution done in particular PID
SELECT a.query, 
       b.starttime, 
       b.endtime, 
       ( b.endtime - b.starttime ) / 1000000 AS duration_sec, 
       Round(a.query_cpu_usage_percent)      AS cpu_usage_percent, 
       Substring(b.querytxt, 1, 80)          AS querytxt 
FROM   svl_query_metrics_summary a, 
       stl_query b 
WHERE  a.query = b.query 
       and b.pid=pg_backend_pid()
       AND b.starttime BETWEEN Dateadd(hour, -1, sysdate) AND sysdate 
       AND a.userid > 1 
ORDER  BY b.starttime DESC;

--See already inflight query and kill them if blocking your query
-- Inflight query (Running Query)
select
  userid
  , query
  , pid
  , starttime
  , text as text
from stv_inflight;

--KIll query
cancel PID;

-- Get the column name and its number for all views 
SELECT trim(pgn.nspname) AS schema_name, 
       trim(pgc.relname) AS view_name,
       det.attnum        AS column_num,
       det.attname       AS column_name,
       def.type          AS data_type
FROM pg_class as pgc
JOIN pg_namespace as pgn on pgn.oid = pgc.relnamespace
LEFT OUTER JOIN (select attrelid, attname, attnum from pg_attribute where attnum>0) as det on det.attrelid = pgc.oid
LEFT OUTER JOIN pg_table_def def on (def.schemaname=pgn.nspname and def.tablename=pgc.relname and def."column"=det.attname)
WHERE schema_name NOT IN ('pg_catalog','pg_toast','information_schema')
AND pgc.relkind ='v' 
order by 1,2,3;

--  list of all the queries running longer then 30 min
select 
  pid, 
  trim(user_name) AS user_name, 
  starttime, 
  query, 
  DATEDIFF(minutes, starttime, getdate()) as delay_in_mints, 
  status
from stv_recents 
where 
  status='Running' and  
  DATEDIFF(minutes, starttime, getdate()) > 30
order by starttime;

-- Get the full querytext of a query stored in chunks of sequence
select query, starttime, text, "sequence" 
from stl_query join stl_querytext using (query) 
order by query,sequence 
limit 100;

-- Get In flight query with username and delay in queue
select 
  a.userid, 
  cast(u.usename as varchar(100)), 
  a.query, 
  a.label, 
  a.pid, 
  a.starttime, 
  DATEDIFF(minutes, a.starttime, getdate()) as delay_in_min, 
  b.query as querytext
from stv_inflight a, stv_recents b, pg_user u
where a.pid = b.pid and a.userid = u.usesysid;

-- Get the locks on table and kill the session 
select 
  table_id, 
  last_update, 
  last_commit, 
  lock_owner_pid, 
  lock_status 
from stv_locks 
order by last_update asc; 

cancel <PID>;

--- Table with its row_count
select
trim(datname)   db_name
,trim(nspname)   schema_name
,trim(relname)   table_name
,sum(rows) as rows
from stv_tbl_perm
join pg_class on pg_class.oid = stv_tbl_perm.id
join pg_namespace on pg_namespace.oid = relnamespace
join pg_database on pg_database.oid = stv_tbl_perm.db_id
where lower(relname) in 
(
‘All your tablenames’
)
group by db_name, schema_name, table_name
order by table_name,db_name, schema_name;


---To provide the queries and metrics running during the cpu spike hours ----
SELECT current_database()::character varying(15)            AS clustername,
       sq.xid,
       sq.pid,
       sqm.query,
       sq.querytxt,
       sq.starttime                                         AS query_starttime,
       sq.endtime                                           AS query_endtime,
       date_diff('seconds'::text, sq.starttime, sq.endtime) AS total_query_execution_time_in_secs,
       sqm.query_queue_time / 1000000                       AS query_queue_time_in_secs,
       sqm.cpu_time / 1000000                               AS cpu_seconds,
       'now'::text::date                                    AS dataset_date,
       'Completed Queries'                                  AS query_type
FROM stl_query_metrics sqm
         JOIN stl_query sq ON sqm.query = sq.query
WHERE sqm.segment = -1
  AND sqm.cpu_time > 1000000000
UNION ALL
SELECT current_database()::character varying(15) AS clustername,
       si.xid,
       si.pid,
       sqm.query,
       si.text                                   AS querytxt,
       si.starttime                              AS query_starttime,
       NULL::"unknown"                           AS query_endtime,
       NULL::"unknown"                           AS total_query_execution_time_in_secs,
       sqm.query_queue_time / 1000000            AS query_queue_time_in_secs,
       sqm.cpu_time / 1000000                    AS cpu_seconds,
       'now'::text::date                         AS dataset_date,
       'Running Queries'                         AS query_type
FROM stv_query_metrics sqm
         JOIN stv_inflight si ON sqm.query = si.query
WHERE sqm.segment = -1
  AND sqm.cpu_time > 1000000000;
  
 
---- To provide the queries and metrics running during the disk space spike hours -----
SELECT current_database()::character varying(15)                                             AS clustername,
       sq.xid,
       sq.query,
       sq.pid,
       sq.querytxt,
       sq.starttime                                                                          AS query_starttime,
       sq.endtime                                                                            AS query_endtime,
       sqms.query_execution_time                                                             AS query_execution_time_secs,
       sqms.query_queue_time                                                                 AS query_queue_time_secs,
       round(qs.data_in_mb::numeric::numeric(18, 0) / 1024.00 / 1024.00, 2)                  AS data_in_tb,
       round(qs.workmem_estimated_mb::numeric::numeric(18, 0) / 1024.00 / 1024.00, 2)        AS workmem_estimated_tb,
       round(sqms.query_blocks_read::numeric::numeric(18, 0) / 1024.00 / 1024.00, 2)         AS query_blocks_read_tb,
       round(sqms.query_temp_blocks_to_disk::numeric::numeric(18, 0) / 1024.00 / 1024.00,
             2)                                                                              AS query_temp_blocks_to_disk_tb,
       'now'::text::date                                                                     AS dataset_date,
       'Completed Queries'                                                                   AS query_type
FROM stl_query sq
         JOIN (SELECT svl_query_summary.query,
                      sum(svl_query_summary.bytes) / 1024 / 1024   AS data_in_mb,
                      sum(svl_query_summary.workmem) / 1024 / 1024 AS workmem_estimated_mb
               FROM svl_query_summary
               WHERE svl_query_summary.is_diskbased = 't'::bpchar
                 AND (svl_query_summary."label"::text ~~* 'hash%'::text OR
                      svl_query_summary."label"::text ~~* 'sort%'::text OR
                      svl_query_summary."label"::text ~~* 'aggr%'::text OR
                      svl_query_summary."label"::text ~~* 'save%'::text OR
                      svl_query_summary."label"::text ~~* 'window%'::text OR
                      svl_query_summary."label"::text ~~* 'unique%'::text)
                 AND svl_query_summary.userid > 1
               GROUP BY svl_query_summary.query) qs ON qs.query = sq.query
         JOIN svl_query_metrics_summary sqms ON sq.query = sqms.query
UNION ALL
SELECT current_database()::character varying(15)                                      AS clustername,
       si.xid,
       si.query,
       si.pid,
       si.text                                                                        AS querytxt,
       si.starttime                                                                   AS query_starttime,
       NULL::"unknown"                                                                AS query_endtime,
       NULL::"unknown"                                                                AS query_execution_time_secs,
       sqm.query_queue_time                                                           AS query_queue_time_secs,
       round(qs.data_in_mb::numeric::numeric(18, 0) / 1024.00 / 1024.00, 2)           AS data_in_tb,
       round(qs.workmem_estimated_mb::numeric::numeric(18, 0) / 1024.00 / 1024.00, 2) AS workmem_estimated_tb,
       round(sqm.blocks_read::numeric::numeric(18, 0) / 1024.00 / 1024.00, 2)         AS query_blocks_read_tb,
       round(sqm.blocks_to_disk::numeric::numeric(18, 0) / 1024.00 / 1024.00, 2)      AS query_temp_blocks_to_disk_tb,
       'now'::text::date                                                              AS dataset_date,
       'Running queries'                                                              AS query_type
FROM stv_inflight si
         JOIN (SELECT svl_query_summary.query,
                      sum(svl_query_summary.bytes) / 1024 / 1024   AS data_in_mb,
                      sum(svl_query_summary.workmem) / 1024 / 1024 AS workmem_estimated_mb
               FROM svl_query_summary
               WHERE svl_query_summary.is_diskbased = 't'::bpchar
                 AND (svl_query_summary."label"::text ~~* 'hash%'::text OR
                      svl_query_summary."label"::text ~~* 'sort%'::text OR
                      svl_query_summary."label"::text ~~* 'aggr%'::text OR
                      svl_query_summary."label"::text ~~* 'save%'::text OR
                      svl_query_summary."label"::text ~~* 'window%'::text OR
                      svl_query_summary."label"::text ~~* 'unique%'::text)
                 AND svl_query_summary.userid > 1
               GROUP BY svl_query_summary.query) qs ON qs.query = si.query
         JOIN stv_query_metrics sqm ON si.query = sqm.query
WHERE sqm.segment = -1;

----- Query Terminator -------
create or replace view test_schema.vw_query_metrics(userid, query, service_class, dimension, segment, step, step_label, query_cpu_time, query_blocks_read, query_execution_time, query_cpu_usage_percent, query_temp_blocks_to_disk, segment_execution_time, cpu_skew, io_skew, scan_row_count, join_row_count, nested_loop_join_row_count, return_row_count, spectrum_scan_row_count, spectrum_scan_size_mb, query_queue_time) as
	SELECT qm.userid,
       qm.query,
       qm.service_class,
       CASE
           WHEN qm.segment = -1 AND qm.step_type = -1 AND qm.step = -1 THEN 'query'::character varying
           WHEN qm.segment > -1 AND qm.step_type = -1 AND qm.step = -1 THEN 'segment'::character varying
           WHEN qm.segment > -1 AND qm.step_type > -1 AND qm.step > -1 THEN 'step'::character varying
           ELSE NULL::character varying
           END::character varying(24)                                    AS dimension,
       CASE
           WHEN qm.segment = -1 THEN NULL::integer
           ELSE qm.segment
           END                                                           AS segment,
       CASE
           WHEN qm.step = -1 THEN NULL::integer
           ELSE qm.step
           END                                                           AS step,
       CASE
           WHEN qm.step_type = 1 THEN 'scan'::character varying
           WHEN qm.step_type = 2 THEN 'insert'::character varying
           WHEN qm.step_type = 3 THEN 'aggr'::character varying
           WHEN qm.step_type = 4 THEN 'return'::character varying
           WHEN qm.step_type = 6 THEN 'sort'::character varying
           WHEN qm.step_type = 7 THEN 'merge'::character varying
           WHEN qm.step_type = 8 THEN 'dist'::character varying
           WHEN qm.step_type = 9 THEN 'bcast'::character varying
           WHEN qm.step_type = 10 THEN 'hjoin'::character varying
           WHEN qm.step_type = 11 THEN 'mjoin'::character varying
           WHEN qm.step_type = 12 THEN 'save'::character varying
           WHEN qm.step_type = 14 THEN 'hash'::character varying
           WHEN qm.step_type = 15 THEN 'nloop'::character varying
           WHEN qm.step_type = 16 THEN 'project'::character varying
           WHEN qm.step_type = 17 THEN 'limit'::character varying
           WHEN qm.step_type = 18 THEN 'unique'::character varying
           WHEN qm.step_type = 20 THEN 'delete'::character varying
           WHEN qm.step_type = 26 THEN 'limit'::character varying
           WHEN qm.step_type = 29 THEN 'window'::character varying
           WHEN qm.step_type = 32 THEN 'udf'::character varying
           WHEN qm.step_type = 33 THEN 'unique'::character varying
           WHEN qm.step_type = 37 THEN 'returnclient'::character varying
           WHEN qm.step_type = 38 THEN 'returnleader'::character varying
           WHEN qm.step_type = 40 THEN 'spectrumscan'::character varying
           ELSE NULL::character varying
           END::character varying(30)                                    AS step_label,
       CASE
           WHEN qm.segment = -1 AND qm.step_type = -1 AND qm.step = -1 THEN ceiling(
                       CASE
                           WHEN "max"(qm.cpu_time)::numeric::numeric(18, 0)::numeric(38, 6) =
                                (- 1::numeric::numeric(18, 0)::numeric(38, 6)) THEN NULL::numeric::numeric(18, 0)
                           ELSE "max"(qm.cpu_time)::numeric::numeric(18, 0)::numeric(38, 6)
                           END / 1000000::numeric::numeric(18, 0)::numeric(38, 6))
           ELSE NULL::numeric::numeric(18, 0)
           END::bigint                                                   AS query_cpu_time,
       CASE
           WHEN qm.segment = -1 AND qm.step_type = -1 AND qm.step = -1 THEN
               CASE
                   WHEN "max"(qm.blocks_read) = -1 THEN NULL::bigint
                   ELSE "max"(qm.blocks_read)
                   END
           ELSE NULL::bigint
           END                                                           AS query_blocks_read,
       ceiling(q.exec_time::numeric::numeric(18, 0)::numeric(38, 6) /
               1000000::numeric::numeric(18, 0)::numeric(38, 6))::bigint AS query_execution_time,
       round(
               CASE
                   WHEN qm.segment = -1 AND qm.step_type = -1 AND qm.step = -1 THEN 100::numeric::numeric(18, 0) *
                                                                                    "max"((
                                                                                                  CASE
                                                                                                      WHEN qm.cpu_time = -1
                                                                                                          THEN NULL::bigint
                                                                                                      ELSE qm.cpu_time
                                                                                                      END::numeric::numeric(18, 0) +
                                                                                                  0.00001) / (
                                                                                                  CASE
                                                                                                      WHEN qm.run_time = -1
                                                                                                          THEN NULL::bigint
                                                                                                      ELSE qm.run_time
                                                                                                      END::numeric::numeric(18, 0) +
                                                                                                  0.00001))
                   ELSE NULL::numeric::numeric(18, 0)
                   END, 2)::numeric(38, 2)                               AS query_cpu_usage_percent,
       CASE
           WHEN qm.segment = -1 AND qm.step_type = -1 AND qm.step = -1 THEN
               CASE
                   WHEN "max"(qm.blocks_to_disk) = -1 THEN NULL::bigint
                   ELSE "max"(qm.blocks_to_disk)
                   END
           ELSE NULL::bigint
           END                                                           AS query_temp_blocks_to_disk,
       CASE
           WHEN qm.segment > -1 AND qm.step_type = -1 THEN ceiling(
                       CASE
                           WHEN "max"(qm.max_run_time) = -1 THEN NULL::bigint
                           ELSE "max"(qm.max_run_time)
                           END::numeric::numeric(18, 0)::numeric(38, 6) /
                       1000000::numeric::numeric(18, 0)::numeric(38, 6))
           ELSE NULL::numeric::numeric(18, 0)
           END::bigint                                                   AS segment_execution_time,
       round(
               CASE
                   WHEN qm.segment > -1 AND qm.step_type = -1 AND "max"(qm.max_cpu_time) > 0 AND "max"(qm.cpu_time) > 0
                       THEN qm.slices::numeric::numeric(18, 0) * "max"((
                                                                               CASE
                                                                                   WHEN qm.max_cpu_time = -1 THEN NULL::bigint
                                                                                   ELSE qm.max_cpu_time
                                                                                   END::numeric::numeric(18, 0) +
                                                                               0.00001) / (
                                                                               CASE
                                                                                   WHEN qm.cpu_time = -1 THEN NULL::bigint
                                                                                   ELSE qm.cpu_time
                                                                                   END::numeric::numeric(18, 0) +
                                                                               0.00001))
                   ELSE NULL::numeric::numeric(18, 0)
                   END, 2)::numeric(38, 2)                               AS cpu_skew,
       round(
               CASE
                   WHEN qm.segment > -1 AND qm.step_type = -1 AND "max"(qm.max_blocks_read) > 0 AND
                        "max"(qm.blocks_read) > 0 THEN qm.slices::numeric::numeric(18, 0) * "max"((
                                                                                                          CASE
                                                                                                              WHEN qm.max_blocks_read = -1
                                                                                                                  THEN NULL::integer
                                                                                                              ELSE qm.max_blocks_read
                                                                                                              END::numeric::numeric(18, 0) +
                                                                                                          0.00001) / (
                                                                                                          CASE
                                                                                                              WHEN qm.blocks_read = -1
                                                                                                                  THEN NULL::bigint
                                                                                                              ELSE qm.blocks_read
                                                                                                              END::numeric::numeric(18, 0) +
                                                                                                          0.00001))
                   ELSE NULL::numeric::numeric(18, 0)
                   END, 2)::numeric(38, 2)                               AS io_skew,
       CASE
           WHEN qm.segment > -1 AND qm.step_type = 1 AND qm.step > -1 THEN
               CASE
                   WHEN "max"(qm."rows") = -1 THEN NULL::bigint
                   ELSE "max"(qm."rows")
                   END
           ELSE NULL::bigint
           END                                                           AS scan_row_count,
       CASE
           WHEN qm.segment > -1 AND (qm.step_type = 10 OR qm.step_type = 11 OR qm.step_type = 15) AND qm.step > -1 THEN
               CASE
                   WHEN "max"(qm."rows") = -1 THEN NULL::bigint
                   ELSE "max"(qm."rows")
                   END
           ELSE NULL::bigint
           END                                                           AS join_row_count,
       CASE
           WHEN qm.segment > -1 AND qm.step_type = 15 AND qm.step > -1 THEN
               CASE
                   WHEN "max"(qm."rows") = -1 THEN NULL::bigint
                   ELSE "max"(qm."rows")
                   END
           ELSE NULL::bigint
           END                                                           AS nested_loop_join_row_count,
       CASE
           WHEN qm.segment > -1 AND qm.step_type = 37 AND qm.step > -1 THEN
               CASE
                   WHEN "max"(qm."rows") = -1 THEN NULL::bigint
                   ELSE "max"(qm."rows")
                   END
           ELSE NULL::bigint
           END                                                           AS return_row_count,
       CASE
           WHEN qm.segment > -1 AND qm.step_type = 40 AND qm.step > -1 THEN
               CASE
                   WHEN "max"(qm."rows") = -1 THEN NULL::bigint
                   ELSE "max"(qm."rows")
                   END
           ELSE NULL::bigint
           END                                                           AS spectrum_scan_row_count,
       CASE
           WHEN qm.segment > -1 AND qm.step_type = 40 AND qm.step > -1 THEN
               CASE
                   WHEN "max"(qm.query_scan_size) = -1 THEN NULL::bigint
                   ELSE "max"(qm.query_scan_size)
                   END
           ELSE NULL::bigint
           END                                                           AS spectrum_scan_size_mb,
       CASE
           WHEN qm.segment = -1 AND qm.step_type = -1 AND qm.step = -1 THEN ceiling(
                       CASE
                           WHEN "max"(qm.query_queue_time) = -1 THEN NULL::bigint
                           ELSE "max"(qm.query_queue_time)
                           END::numeric::numeric(18, 0)::numeric(38, 6) /
                       1000000::numeric::numeric(18, 0)::numeric(38, 6))
           ELSE NULL::numeric::numeric(18, 0)
           END::bigint                                                   AS query_queue_time
FROM stv_query_metrics qm
         JOIN stv_wlm_query_state q USING (service_class, query)
GROUP BY qm.userid, qm.query, qm.service_class, qm.slices, qm.segment, qm.step_type, qm.step, q.exec_time;


create or replace view test_schema.vw_query_metrics_summary(userid, query, service_class, query_cpu_time, query_blocks_read, query_execution_time, query_cpu_usage_percent, query_temp_blocks_to_disk, segment_execution_time, cpu_skew, io_skew, scan_row_count, join_row_count, nested_loop_join_row_count, return_row_count, spectrum_scan_row_count, spectrum_scan_size_mb, query_queue_time) as
	SELECT svl_query_metrics.userid,
       svl_query_metrics.query,
       svl_query_metrics.service_class,
       "max"(svl_query_metrics.query_cpu_time)             AS query_cpu_time,
       "max"(svl_query_metrics.query_blocks_read)          AS query_blocks_read,
       "max"(svl_query_metrics.query_execution_time)       AS query_execution_time,
       "max"(svl_query_metrics.query_cpu_usage_percent)    AS query_cpu_usage_percent,
       "max"(svl_query_metrics.query_temp_blocks_to_disk)  AS query_temp_blocks_to_disk,
       "max"(svl_query_metrics.segment_execution_time)     AS segment_execution_time,
       "max"(svl_query_metrics.cpu_skew)                   AS cpu_skew,
       "max"(svl_query_metrics.io_skew)                    AS io_skew,
       "max"(svl_query_metrics.scan_row_count)             AS scan_row_count,
       "max"(svl_query_metrics.join_row_count)             AS join_row_count,
       "max"(svl_query_metrics.nested_loop_join_row_count) AS nested_loop_join_row_count,
       "max"(svl_query_metrics.return_row_count)           AS return_row_count,
       "max"(svl_query_metrics.spectrum_scan_row_count)    AS spectrum_scan_row_count,
       "max"(svl_query_metrics.spectrum_scan_size_mb)      AS spectrum_scan_size_mb,
       "max"(svl_query_metrics.query_queue_time)           AS query_queue_time
FROM test_schema.vw_query_metrics svl_query_metrics
GROUP BY svl_query_metrics.userid, svl_query_metrics.query, svl_query_metrics.service_class;
